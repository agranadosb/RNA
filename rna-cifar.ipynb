{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 11:51:01.316855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-08 11:51:01.326123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-08 11:51:01.326678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-08 11:51:01.328424: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-08 11:51:01.329986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-08 11:51:01.330638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-08 11:51:01.331262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-08 11:51:01.742568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-08 11:51:01.742854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-08 11:51:01.743090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-08 11:51:01.743323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2324 MB memory:  -> device: 0, name: GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 3)   12          ['input_1[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 32)   896         ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 32, 32, 32)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 32)  128         ['re_lu[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 64)   18496       ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 32, 32, 64)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 64)  256         ['re_lu_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 64)   18496       ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 64)   36928       ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 32, 32, 64)   0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 32, 32, 64)   0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 64)  256         ['re_lu_3[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 64)  256         ['re_lu_2[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 32, 32, 64)   0           ['batch_normalization_4[0][0]',  \n",
      "                                                                  'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 32, 32, 64)   0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 32, 64)  256         ['re_lu_4[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 16, 16, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 16, 16, 128)  73856       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 16, 16, 128)  0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 16, 128)  512        ['re_lu_5[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 16, 128)  73856       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 16, 16, 128)  147584      ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 16, 16, 128)  0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 16, 16, 128)  0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 128)  512        ['re_lu_7[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 128)  512        ['re_lu_6[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 16, 16, 128)  0           ['batch_normalization_8[0][0]',  \n",
      "                                                                  'batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 16, 16, 128)  0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 16, 128)  512        ['re_lu_8[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 128)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 8, 8, 256)    295168      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)                 (None, 8, 8, 256)    0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 8, 8, 256)   1024        ['re_lu_9[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 8, 8, 256)    295168      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 8, 8, 256)    590080      ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)                (None, 8, 8, 256)    0           ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)                (None, 8, 8, 256)    0           ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 8, 8, 256)   1024        ['re_lu_11[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 8, 8, 256)   1024        ['re_lu_10[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 8, 8, 256)    0           ['batch_normalization_12[0][0]', \n",
      "                                                                  'batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)                (None, 8, 8, 256)    0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 8, 8, 256)   1024        ['re_lu_12[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 256)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 4, 4, 512)    1180160     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)                (None, 4, 4, 512)    0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 4, 4, 512)   2048        ['re_lu_13[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 4, 4, 512)    1180160     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 4, 4, 512)    2359808     ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_15 (ReLU)                (None, 4, 4, 512)    0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)                (None, 4, 4, 512)    0           ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 4, 4, 512)   2048        ['re_lu_15[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 4, 4, 512)   2048        ['re_lu_14[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 4, 4, 512)    0           ['batch_normalization_16[0][0]', \n",
      "                                                                  'batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_16 (ReLU)                (None, 4, 4, 512)    0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 4, 4, 512)   2048        ['re_lu_16[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 512)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 2, 2, 1024)   4719616     ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " re_lu_17 (ReLU)                (None, 2, 2, 1024)   0           ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 2, 2, 1024)  4096        ['re_lu_17[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 2, 2, 1024)   4719616     ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 2, 2, 1024)   9438208     ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_19 (ReLU)                (None, 2, 2, 1024)   0           ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_18 (ReLU)                (None, 2, 2, 1024)   0           ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 2, 2, 1024)  4096        ['re_lu_19[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 2, 2, 1024)  4096        ['re_lu_18[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 2, 2, 1024)   0           ['batch_normalization_20[0][0]', \n",
      "                                                                  'batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)                (None, 2, 2, 1024)   0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 2, 2, 1024)  4096        ['re_lu_20[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 1024)  0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1024)         0           ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 10)           10250       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25,190,230\n",
      "Trainable params: 25,174,288\n",
      "Non-trainable params: 15,942\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 11:51:04.298133: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8202\n",
      "2022-01-08 11:51:06.136261: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-01-08 11:51:06.136331: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-01-08 11:51:06.284983: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.44GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-01-08 11:51:06.285045: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.44GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-01-08 11:51:06.489218: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-01-08 11:51:06.489287: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-01-08 11:51:06.640993: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.44GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-01-08 11:51:06.641055: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.44GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-01-08 11:51:06.959806: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-01-08 11:51:06.959869: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937/937 [==============================] - 126s 128ms/step - loss: 2.5840 - accuracy: 0.2935 - val_loss: 2.7583 - val_accuracy: 0.1564 - lr: 0.1000\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 110s 117ms/step - loss: 1.6854 - accuracy: 0.3880 - val_loss: 8.5398 - val_accuracy: 0.3497 - lr: 0.1000\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 111s 118ms/step - loss: 6.7976 - accuracy: 0.3410 - val_loss: 35794.0430 - val_accuracy: 0.3094 - lr: 0.1000\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 109s 117ms/step - loss: 1.5701 - accuracy: 0.4267 - val_loss: 1615086212874240.0000 - val_accuracy: 0.3634 - lr: 0.1000\n",
      "Epoch 5/100\n",
      " 55/937 [>.............................] - ETA: 1:41 - loss: 1.4056 - accuracy: 0.4918"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38654/819244733.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_res_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# or create_plain_net()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/proyectos/burn-region-detection/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/proyectos/burn-region-detection/.venv/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/proyectos/burn-region-detection/.venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/proyectos/burn-region-detection/.venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/proyectos/burn-region-detection/.venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/proyectos/burn-region-detection/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/proyectos/burn-region-detection/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/proyectos/burn-region-detection/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/proyectos/burn-region-detection/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "import tensorflow as tf\n",
    "from albumentations import CoarseDropout, Compose, HorizontalFlip, RandomBrightness\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Activation, Add\n",
    "from tensorflow.keras.layers import BatchNormalization as BN\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten\n",
    "from tensorflow.keras.layers import GaussianNoise as GN\n",
    "from tensorflow.keras.layers import Input, MaxPooling2D\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "batch_size = 400\n",
    "epochs = 100\n",
    "num_classes = 10\n",
    "transforms = Compose(\n",
    "    [\n",
    "        RandomBrightness(limit=0.1, p=0.5),\n",
    "        CoarseDropout(max_holes=1, max_height=2, max_width=2, p=0.5),\n",
    "        HorizontalFlip(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def normalize(image, tag):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.divide(image, 255)\n",
    "    return image, tag\n",
    "\n",
    "\n",
    "def sample_beta_distribution(size, concentration_0=0.2, concentration_1=0.2):\n",
    "    gamma_1_sample = tf.random.gamma(shape=[size], alpha=concentration_1)\n",
    "    gamma_2_sample = tf.random.gamma(shape=[size], alpha=concentration_0)\n",
    "    return gamma_1_sample / (gamma_1_sample + gamma_2_sample)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def mix_up(ds_one, ds_two, alpha=0.2):\n",
    "    # Unpack two datasets\n",
    "    images_one, labels_one = ds_one\n",
    "    images_two, labels_two = ds_two\n",
    "\n",
    "    batch_size = tf.shape(images_one)[0]\n",
    "\n",
    "    # Sample lambda and reshape it to do the mixup\n",
    "    l = sample_beta_distribution(batch_size, alpha, alpha)\n",
    "    x_l = tf.reshape(l, (batch_size, 1, 1, 1))\n",
    "    y_l = tf.reshape(l, (batch_size, 1))\n",
    "\n",
    "    # Perform mixup on both images and labels by combining a pair of images/labels\n",
    "    # (one from each dataset) into one image/label\n",
    "    images = images_one * x_l + images_two * (1 - x_l)\n",
    "    labels = labels_one * y_l + labels_two * (1 - y_l)\n",
    "\n",
    "    return (images, labels)\n",
    "\n",
    "\n",
    "def aug_fn(image):\n",
    "    data = {\"image\": image}\n",
    "    aug_data = transforms(**data)\n",
    "    aug_img = aug_data[\"image\"]\n",
    "    aug_img = tf.image.resize(aug_img, size=[32, 32])\n",
    "    return aug_img\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def apply_transformation(image):\n",
    "    return tf.numpy_function(func=aug_fn, inp=[image], Tout=tf.float32)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def process_data(image, label):\n",
    "    tensor = tf.map_fn(apply_transformation, image)\n",
    "    return tensor, label\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "steps_per_epoch = len(x_train) // batch_size\n",
    "\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "train_ds_one = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    .map(normalize)\n",
    "    .shuffle(100)\n",
    "    .repeat(epochs)\n",
    "    .batch(batch_size)\n",
    ")\n",
    "train_ds_two = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    .map(normalize)\n",
    "    .shuffle(100)\n",
    "    .repeat(epochs)\n",
    "    .batch(batch_size)\n",
    ")\n",
    "\n",
    "train_ds = tf.data.Dataset.zip((train_ds_one, train_ds_two))\n",
    "\n",
    "test = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    .map(normalize)\n",
    "    .batch(batch_size)\n",
    ")\n",
    "train = train_ds.map(\n",
    "    lambda ds_one, ds_two: mix_up(ds_one, ds_two, alpha=0.2), num_parallel_calls=AUTO\n",
    ").map(partial(process_data), num_parallel_calls=AUTO)\n",
    "\n",
    "\n",
    "input_shape = (32, 32, 3)\n",
    "gn_prob = 0.3\n",
    "dp_prob = 0.3\n",
    "filters = [32, 64, 128, 256]\n",
    "\n",
    "\n",
    "def activation(x):\n",
    "    y = BN()(x)\n",
    "    y = GN(gn_prob)(y)\n",
    "    y = Activation(\"relu\")(y)\n",
    "    return y\n",
    "\n",
    "\n",
    "def dense_layer(x, n, activation):\n",
    "    x = Dense(n)(x)\n",
    "    x = BN()(x)\n",
    "    x = GN(gn_prob)(x)\n",
    "    x = Activation(activation)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def layer(x, filters):\n",
    "    x = Conv2D(filters, 3, strides=1, padding=\"same\")(x)\n",
    "    x = activation(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def layer_residual(x, filters_output):\n",
    "    input_tensor = layer(x, filters_output)\n",
    "    input_tensor = MaxPooling2D(2)(input_tensor)\n",
    "\n",
    "    x = layer(input_tensor, filters_output)\n",
    "    x = layer(x, filters_output)\n",
    "\n",
    "    out = Add()([x, input_tensor])\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def conv_subnet(x):\n",
    "    x = layer(x, 64)\n",
    "    x = layer_residual(x, 128)\n",
    "\n",
    "    x = layer(x, 256)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    x = layer_residual(x, 512)\n",
    "\n",
    "    x = MaxPooling2D(4)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def input_subnet():\n",
    "    x_input = Input(input_shape)\n",
    "    x = BN()(x_input)\n",
    "    return x, x_input\n",
    "\n",
    "\n",
    "def dense_subnet(x):\n",
    "    x = dense_layer(x, num_classes, \"softmax\")\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_network():\n",
    "    x, x_input = input_subnet()\n",
    "    x = conv_subnet(x)\n",
    "    x = dense_subnet(x)\n",
    "\n",
    "    return tf.keras.models.Model(inputs=x_input, outputs=x, name=\"ResNet\")\n",
    "\n",
    "\n",
    "model = build_network()\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "set_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.8, patience=7, min_lr=1e-6)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "tf.keras.utils.plot_model(model)\n",
    "\n",
    "model.fit(\n",
    "    train,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    validation_data=test,\n",
    "    callbacks=[set_lr],\n",
    ")\n",
    "\n",
    "scores = model.evaluate(test, verbose=1)\n",
    "print(\"Test loss:\", scores[0])\n",
    "print(\"Test accuracy:\", scores[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a574ebe25ba7c7aaf3824aa551855f88c0879d5c5c83cc50c0532cd155652f26"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
