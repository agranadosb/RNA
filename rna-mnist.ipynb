{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set (60000, 28, 28)\n",
      "test set (10000, 28, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 21:20:45.113265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-04 21:20:45.118327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-04 21:20:45.118731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-04 21:20:45.119395: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-04 21:20:45.120940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-04 21:20:45.121300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-04 21:20:45.121539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-04 21:20:45.598930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-04 21:20:45.599327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-04 21:20:45.599827: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-04 21:20:45.600119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2199 MB memory:  -> device: 0, name: GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 784)               0         \n",
      "                                                                 \n",
      " gaussian_noise (GaussianNoi  (None, 784)              0         \n",
      " se)                                                             \n",
      "                                                                 \n",
      " dense_block0 (Dense)        (None, 1024)              803840    \n",
      "                                                                 \n",
      " bach_normalization_block0 (  (None, 1024)             4096      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " gaussian_noise_block0 (Gaus  (None, 1024)             0         \n",
      " sianNoise)                                                      \n",
      "                                                                 \n",
      " relu_block0 (Activation)    (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_block1 (Dense)        (None, 1024)              1049600   \n",
      "                                                                 \n",
      " bach_normalization_block1 (  (None, 1024)             4096      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " gaussian_noise_block1 (Gaus  (None, 1024)             0         \n",
      " sianNoise)                                                      \n",
      "                                                                 \n",
      " relu_block1 (Activation)    (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_block2 (Dense)        (None, 1024)              1049600   \n",
      "                                                                 \n",
      " bach_normalization_block2 (  (None, 1024)             4096      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " gaussian_noise_block2 (Gaus  (None, 1024)             0         \n",
      " sianNoise)                                                      \n",
      "                                                                 \n",
      " relu_block2 (Activation)    (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_block3 (Dense)        (None, 1024)              1049600   \n",
      "                                                                 \n",
      " bach_normalization_block3 (  (None, 1024)             4096      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " gaussian_noise_block3 (Gaus  (None, 1024)             0         \n",
      " sianNoise)                                                      \n",
      "                                                                 \n",
      " relu_block3 (Activation)    (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_block4 (Dense)        (None, 1024)              1049600   \n",
      "                                                                 \n",
      " bach_normalization_block4 (  (None, 1024)             4096      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " gaussian_noise_block4 (Gaus  (None, 1024)             0         \n",
      " sianNoise)                                                      \n",
      "                                                                 \n",
      " relu_block4 (Activation)    (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,032,970\n",
      "Trainable params: 5,022,730\n",
      "Non-trainable params: 10,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 17s 26ms/step - loss: 1.2429 - accuracy: 0.6704 - val_loss: 0.2154 - val_accuracy: 0.9359 - lr: 0.1000\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.4845 - accuracy: 0.8538 - val_loss: 0.1482 - val_accuracy: 0.9579 - lr: 0.1000\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.4094 - accuracy: 0.8771 - val_loss: 0.1555 - val_accuracy: 0.9566 - lr: 0.1000\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 17s 29ms/step - loss: 0.3669 - accuracy: 0.8908 - val_loss: 0.1011 - val_accuracy: 0.9709 - lr: 0.1000\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.3391 - accuracy: 0.8990 - val_loss: 0.0992 - val_accuracy: 0.9722 - lr: 0.1000\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 17s 29ms/step - loss: 0.3223 - accuracy: 0.9053 - val_loss: 0.0994 - val_accuracy: 0.9723 - lr: 0.1000\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.3040 - accuracy: 0.9106 - val_loss: 0.0859 - val_accuracy: 0.9778 - lr: 0.1000\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 17s 29ms/step - loss: 0.2931 - accuracy: 0.9158 - val_loss: 0.1007 - val_accuracy: 0.9740 - lr: 0.1000\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.2862 - accuracy: 0.9183 - val_loss: 0.0856 - val_accuracy: 0.9759 - lr: 0.1000\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.2776 - accuracy: 0.9202 - val_loss: 0.0726 - val_accuracy: 0.9789 - lr: 0.1000\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.2684 - accuracy: 0.9240 - val_loss: 0.0830 - val_accuracy: 0.9788 - lr: 0.1000\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.2590 - accuracy: 0.9262 - val_loss: 0.1616 - val_accuracy: 0.9489 - lr: 0.1000\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.2425 - accuracy: 0.9316 - val_loss: 0.3581 - val_accuracy: 0.9351 - lr: 0.1000\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.2502 - accuracy: 0.9288 - val_loss: 0.0701 - val_accuracy: 0.9813 - lr: 0.1000\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.2306 - accuracy: 0.9343 - val_loss: 0.9772 - val_accuracy: 0.9012 - lr: 0.1000\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.2297 - accuracy: 0.9342 - val_loss: 0.1100 - val_accuracy: 0.9787 - lr: 0.1000\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.2262 - accuracy: 0.9352 - val_loss: 0.0635 - val_accuracy: 0.9819 - lr: 0.1000\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.2099 - accuracy: 0.9399 - val_loss: 0.6855 - val_accuracy: 0.8997 - lr: 0.1000\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.2115 - accuracy: 0.9399 - val_loss: 0.0538 - val_accuracy: 0.9844 - lr: 0.1000\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.2113 - accuracy: 0.9407 - val_loss: 0.0583 - val_accuracy: 0.9847 - lr: 0.1000\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 16s 26ms/step - loss: 0.2022 - accuracy: 0.9418 - val_loss: 0.0536 - val_accuracy: 0.9847 - lr: 0.1000\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.1979 - accuracy: 0.9447 - val_loss: 0.1254 - val_accuracy: 0.9784 - lr: 0.1000\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.1964 - accuracy: 0.9454 - val_loss: 0.0500 - val_accuracy: 0.9866 - lr: 0.1000\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.1870 - accuracy: 0.9469 - val_loss: 0.1759 - val_accuracy: 0.9650 - lr: 0.1000\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.1897 - accuracy: 0.9479 - val_loss: 0.0465 - val_accuracy: 0.9860 - lr: 0.1000\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.1821 - accuracy: 0.9490 - val_loss: 0.0429 - val_accuracy: 0.9868 - lr: 0.1000\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.1773 - accuracy: 0.9504 - val_loss: 0.0551 - val_accuracy: 0.9842 - lr: 0.1000\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.1822 - accuracy: 0.9488 - val_loss: 0.0469 - val_accuracy: 0.9847 - lr: 0.1000\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.1769 - accuracy: 0.9513 - val_loss: 0.0468 - val_accuracy: 0.9869 - lr: 0.1000\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.1809 - accuracy: 0.9503 - val_loss: 0.0560 - val_accuracy: 0.9832 - lr: 0.1000\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.1731 - accuracy: 0.9516 - val_loss: 0.0978 - val_accuracy: 0.9736 - lr: 0.1000\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 18s 30ms/step - loss: 0.1681 - accuracy: 0.9537 - val_loss: 0.0411 - val_accuracy: 0.9888 - lr: 0.1000\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.1638 - accuracy: 0.9542 - val_loss: 0.0361 - val_accuracy: 0.9883 - lr: 0.1000\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.1612 - accuracy: 0.9549 - val_loss: 0.0597 - val_accuracy: 0.9861 - lr: 0.1000\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 15s 26ms/step - loss: 0.1555 - accuracy: 0.9559 - val_loss: 0.0440 - val_accuracy: 0.9882 - lr: 0.1000\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.1585 - accuracy: 0.9557 - val_loss: 0.0554 - val_accuracy: 0.9849 - lr: 0.1000\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 16s 26ms/step - loss: 0.1518 - accuracy: 0.9566 - val_loss: 0.0403 - val_accuracy: 0.9884 - lr: 0.1000\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 16s 26ms/step - loss: 0.1513 - accuracy: 0.9582 - val_loss: 0.0381 - val_accuracy: 0.9886 - lr: 0.1000\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.1481 - accuracy: 0.9587 - val_loss: 0.0449 - val_accuracy: 0.9880 - lr: 0.1000\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.1488 - accuracy: 0.9583 - val_loss: 0.0342 - val_accuracy: 0.9892 - lr: 0.1000\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.1434 - accuracy: 0.9604 - val_loss: 0.0434 - val_accuracy: 0.9881 - lr: 0.1000\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.1598 - accuracy: 0.9579 - val_loss: 0.0608 - val_accuracy: 0.9850 - lr: 0.1000\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.1618 - accuracy: 0.9574 - val_loss: 0.0486 - val_accuracy: 0.9858 - lr: 0.1000\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.1483 - accuracy: 0.9599 - val_loss: 0.0373 - val_accuracy: 0.9883 - lr: 0.1000\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.1431 - accuracy: 0.9604 - val_loss: 0.0379 - val_accuracy: 0.9884 - lr: 0.1000\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.1393 - accuracy: 0.9607 - val_loss: 0.0335 - val_accuracy: 0.9903 - lr: 0.1000\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.1474 - accuracy: 0.9607 - val_loss: 0.0432 - val_accuracy: 0.9881 - lr: 0.1000\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.1370 - accuracy: 0.9619 - val_loss: 0.0478 - val_accuracy: 0.9865 - lr: 0.1000\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 16s 26ms/step - loss: 0.1385 - accuracy: 0.9619 - val_loss: 0.0440 - val_accuracy: 0.9878 - lr: 0.1000\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.1322 - accuracy: 0.9616 - val_loss: 0.0359 - val_accuracy: 0.9897 - lr: 0.1000\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 18s 30ms/step - loss: 0.1329 - accuracy: 0.9626 - val_loss: 0.0418 - val_accuracy: 0.9888 - lr: 0.1000\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 16s 26ms/step - loss: 0.1379 - accuracy: 0.9620 - val_loss: 0.0446 - val_accuracy: 0.9885 - lr: 0.1000\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.1343 - accuracy: 0.9631 - val_loss: 0.0330 - val_accuracy: 0.9911 - lr: 0.1000\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.1318 - accuracy: 0.9634 - val_loss: 0.0396 - val_accuracy: 0.9886 - lr: 0.1000\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.1289 - accuracy: 0.9645 - val_loss: 0.0364 - val_accuracy: 0.9901 - lr: 0.1000\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.1303 - accuracy: 0.9647 - val_loss: 0.0410 - val_accuracy: 0.9881 - lr: 0.1000\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.1265 - accuracy: 0.9650 - val_loss: 0.0462 - val_accuracy: 0.9876 - lr: 0.1000\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 16s 26ms/step - loss: 0.1270 - accuracy: 0.9648 - val_loss: 0.0425 - val_accuracy: 0.9881 - lr: 0.1000\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.1408 - accuracy: 0.9616 - val_loss: 0.0359 - val_accuracy: 0.9901 - lr: 0.1000\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.1349 - accuracy: 0.9638 - val_loss: 0.0325 - val_accuracy: 0.9901 - lr: 0.1000\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.1211 - accuracy: 0.9662 - val_loss: 0.0355 - val_accuracy: 0.9892 - lr: 0.1000\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 17s 29ms/step - loss: 0.1251 - accuracy: 0.9657 - val_loss: 0.0355 - val_accuracy: 0.9904 - lr: 0.1000\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.1361 - accuracy: 0.9648 - val_loss: 0.0311 - val_accuracy: 0.9907 - lr: 0.1000\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.1224 - accuracy: 0.9664 - val_loss: 0.0381 - val_accuracy: 0.9903 - lr: 0.1000\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 15s 26ms/step - loss: 0.1204 - accuracy: 0.9659 - val_loss: 0.0424 - val_accuracy: 0.9888 - lr: 0.1000\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 15s 24ms/step - loss: 0.1246 - accuracy: 0.9660 - val_loss: 0.0445 - val_accuracy: 0.9888 - lr: 0.1000\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.1191 - accuracy: 0.9668 - val_loss: 0.0326 - val_accuracy: 0.9920 - lr: 0.1000\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.1296 - accuracy: 0.9646 - val_loss: 0.0438 - val_accuracy: 0.9884 - lr: 0.1000\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.1272 - accuracy: 0.9655 - val_loss: 0.0322 - val_accuracy: 0.9909 - lr: 0.1000\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.1159 - accuracy: 0.9674 - val_loss: 0.0340 - val_accuracy: 0.9913 - lr: 0.1000\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 17s 29ms/step - loss: 0.1163 - accuracy: 0.9678 - val_loss: 0.0402 - val_accuracy: 0.9887 - lr: 0.1000\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 16s 26ms/step - loss: 0.1177 - accuracy: 0.9674 - val_loss: 0.0378 - val_accuracy: 0.9897 - lr: 0.1000\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.1165 - accuracy: 0.9682 - val_loss: 0.0389 - val_accuracy: 0.9904 - lr: 0.1000\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0911 - accuracy: 0.9735 - val_loss: 0.0239 - val_accuracy: 0.9929 - lr: 0.0200\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0838 - accuracy: 0.9750 - val_loss: 0.0230 - val_accuracy: 0.9930 - lr: 0.0200\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0778 - accuracy: 0.9768 - val_loss: 0.0222 - val_accuracy: 0.9925 - lr: 0.0200\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 18s 30ms/step - loss: 0.0757 - accuracy: 0.9770 - val_loss: 0.0217 - val_accuracy: 0.9934 - lr: 0.0200\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0762 - accuracy: 0.9773 - val_loss: 0.0211 - val_accuracy: 0.9938 - lr: 0.0200\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0755 - accuracy: 0.9772 - val_loss: 0.0202 - val_accuracy: 0.9935 - lr: 0.0200\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 17s 29ms/step - loss: 0.0721 - accuracy: 0.9776 - val_loss: 0.0207 - val_accuracy: 0.9934 - lr: 0.0200\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0727 - accuracy: 0.9780 - val_loss: 0.0188 - val_accuracy: 0.9940 - lr: 0.0200\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 17s 29ms/step - loss: 0.0709 - accuracy: 0.9783 - val_loss: 0.0198 - val_accuracy: 0.9941 - lr: 0.0200\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0716 - accuracy: 0.9778 - val_loss: 0.0196 - val_accuracy: 0.9935 - lr: 0.0200\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0713 - accuracy: 0.9783 - val_loss: 0.0203 - val_accuracy: 0.9937 - lr: 0.0200\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0686 - accuracy: 0.9786 - val_loss: 0.0185 - val_accuracy: 0.9943 - lr: 0.0200\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0679 - accuracy: 0.9791 - val_loss: 0.0184 - val_accuracy: 0.9938 - lr: 0.0200\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0686 - accuracy: 0.9789 - val_loss: 0.0211 - val_accuracy: 0.9936 - lr: 0.0200\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 17s 29ms/step - loss: 0.0664 - accuracy: 0.9797 - val_loss: 0.0239 - val_accuracy: 0.9923 - lr: 0.0200\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0672 - accuracy: 0.9790 - val_loss: 0.0197 - val_accuracy: 0.9930 - lr: 0.0200\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0679 - accuracy: 0.9795 - val_loss: 0.0204 - val_accuracy: 0.9937 - lr: 0.0200\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0678 - accuracy: 0.9797 - val_loss: 0.0195 - val_accuracy: 0.9941 - lr: 0.0200\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0660 - accuracy: 0.9796 - val_loss: 0.0200 - val_accuracy: 0.9944 - lr: 0.0200\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0655 - accuracy: 0.9798 - val_loss: 0.0193 - val_accuracy: 0.9940 - lr: 0.0200\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0631 - accuracy: 0.9803 - val_loss: 0.0219 - val_accuracy: 0.9925 - lr: 0.0200\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0651 - accuracy: 0.9798 - val_loss: 0.0200 - val_accuracy: 0.9938 - lr: 0.0200\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 16s 26ms/step - loss: 0.0604 - accuracy: 0.9809 - val_loss: 0.0191 - val_accuracy: 0.9940 - lr: 0.0040\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0596 - accuracy: 0.9812 - val_loss: 0.0191 - val_accuracy: 0.9938 - lr: 0.0040\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.0592 - accuracy: 0.9817 - val_loss: 0.0189 - val_accuracy: 0.9935 - lr: 0.0040\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0574 - accuracy: 0.9819 - val_loss: 0.0185 - val_accuracy: 0.9936 - lr: 0.0040\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.0579 - accuracy: 0.9815 - val_loss: 0.0177 - val_accuracy: 0.9939 - lr: 0.0040\n",
      "Test loss: 0.017669979482889175\n",
      "Test accuracy: 0.9939000010490417\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Ejecuci√≥n consola\\n\\nEpoch 1/100\\n600/600 [==============================] - 15s 22ms/step - loss: 1.1919 - accuracy: 0.6427 - val_loss: 0.2582 - val_accuracy: 0.9230 - lr: 0.1000\\nEpoch 2/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.4901 - accuracy: 0.8518 - val_loss: 0.2221 - val_accuracy: 0.9478 - lr: 0.1000\\nEpoch 3/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.4132 - accuracy: 0.8780 - val_loss: 0.3221 - val_accuracy: 0.9016 - lr: 0.1000\\nEpoch 4/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.3655 - accuracy: 0.8910 - val_loss: 0.0993 - val_accuracy: 0.9717 - lr: 0.1000\\nEpoch 5/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.3465 - accuracy: 0.8984 - val_loss: 0.1308 - val_accuracy: 0.9624 - lr: 0.1000\\nEpoch 6/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.3221 - accuracy: 0.9059 - val_loss: 0.0968 - val_accuracy: 0.9736 - lr: 0.1000\\nEpoch 7/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.3043 - accuracy: 0.9124 - val_loss: 0.0806 - val_accuracy: 0.9767 - lr: 0.1000\\nEpoch 8/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.2884 - accuracy: 0.9161 - val_loss: 0.1014 - val_accuracy: 0.9706 - lr: 0.1000\\nEpoch 9/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.2848 - accuracy: 0.9176 - val_loss: 0.0780 - val_accuracy: 0.9772 - lr: 0.1000\\nEpoch 10/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.2754 - accuracy: 0.9197 - val_loss: 0.0847 - val_accuracy: 0.9745 - lr: 0.1000\\nEpoch 11/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.2642 - accuracy: 0.9229 - val_loss: 0.0913 - val_accuracy: 0.9753 - lr: 0.1000\\nEpoch 12/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.2550 - accuracy: 0.9281 - val_loss: 0.0695 - val_accuracy: 0.9794 - lr: 0.1000\\nEpoch 13/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.2534 - accuracy: 0.9274 - val_loss: 0.2987 - val_accuracy: 0.9390 - lr: 0.1000\\nEpoch 14/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.2407 - accuracy: 0.9307 - val_loss: 0.5038 - val_accuracy: 0.8951 - lr: 0.1000\\nEpoch 15/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.2343 - accuracy: 0.9328 - val_loss: 0.0534 - val_accuracy: 0.9837 - lr: 0.1000\\nEpoch 16/100\\n600/600 [==============================] - 13s 21ms/step - loss: 0.2287 - accuracy: 0.9352 - val_loss: 0.0569 - val_accuracy: 0.9839 - lr: 0.1000\\nEpoch 17/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.2260 - accuracy: 0.9364 - val_loss: 0.1279 - val_accuracy: 0.9662 - lr: 0.1000\\nEpoch 18/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.2208 - accuracy: 0.9373 - val_loss: 0.0585 - val_accuracy: 0.9835 - lr: 0.1000\\nEpoch 19/100\\n600/600 [==============================] - 13s 21ms/step - loss: 0.2166 - accuracy: 0.9384 - val_loss: 0.0603 - val_accuracy: 0.9841 - lr: 0.1000\\nEpoch 20/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.2072 - accuracy: 0.9423 - val_loss: 0.8044 - val_accuracy: 0.8699 - lr: 0.1000\\nEpoch 21/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.2021 - accuracy: 0.9431 - val_loss: 0.0589 - val_accuracy: 0.9853 - lr: 0.1000\\nEpoch 22/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.2013 - accuracy: 0.9443 - val_loss: 0.0469 - val_accuracy: 0.9859 - lr: 0.1000\\nEpoch 23/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.1923 - accuracy: 0.9463 - val_loss: 0.0537 - val_accuracy: 0.9843 - lr: 0.1000\\nEpoch 24/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.1892 - accuracy: 0.9467 - val_loss: 3.1876 - val_accuracy: 0.8846 - lr: 0.1000\\nEpoch 25/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1923 - accuracy: 0.9464 - val_loss: 0.0537 - val_accuracy: 0.9845 - lr: 0.1000\\nEpoch 26/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1829 - accuracy: 0.9499 - val_loss: 0.0479 - val_accuracy: 0.9865 - lr: 0.1000\\nEpoch 27/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1810 - accuracy: 0.9493 - val_loss: 0.0522 - val_accuracy: 0.9856 - lr: 0.1000\\nEpoch 28/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1774 - accuracy: 0.9509 - val_loss: 1.4947 - val_accuracy: 0.8946 - lr: 0.1000\\nEpoch 29/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1766 - accuracy: 0.9503 - val_loss: 0.0561 - val_accuracy: 0.9840 - lr: 0.1000\\nEpoch 30/100\\n600/600 [==============================] - 13s 21ms/step - loss: 0.1729 - accuracy: 0.9522 - val_loss: 0.0428 - val_accuracy: 0.9872 - lr: 0.1000\\nEpoch 31/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.1738 - accuracy: 0.9509 - val_loss: 0.0505 - val_accuracy: 0.9871 - lr: 0.1000\\nEpoch 32/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1775 - accuracy: 0.9510 - val_loss: 0.0388 - val_accuracy: 0.9891 - lr: 0.1000\\nEpoch 33/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.1707 - accuracy: 0.9528 - val_loss: 0.1848 - val_accuracy: 0.9352 - lr: 0.1000\\nEpoch 34/100\\n600/600 [==============================] - 13s 21ms/step - loss: 0.1642 - accuracy: 0.9548 - val_loss: 0.0581 - val_accuracy: 0.9863 - lr: 0.1000\\nEpoch 35/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1688 - accuracy: 0.9534 - val_loss: 0.0425 - val_accuracy: 0.9877 - lr: 0.1000\\nEpoch 36/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1574 - accuracy: 0.9568 - val_loss: 0.0395 - val_accuracy: 0.9892 - lr: 0.1000\\nEpoch 37/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1648 - accuracy: 0.9555 - val_loss: 0.0382 - val_accuracy: 0.9886 - lr: 0.1000\\nEpoch 38/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1547 - accuracy: 0.9572 - val_loss: 0.0411 - val_accuracy: 0.9898 - lr: 0.1000\\nEpoch 39/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1694 - accuracy: 0.9546 - val_loss: 0.0384 - val_accuracy: 0.9887 - lr: 0.1000\\nEpoch 40/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1620 - accuracy: 0.9558 - val_loss: 0.0458 - val_accuracy: 0.9866 - lr: 0.1000\\nEpoch 41/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1518 - accuracy: 0.9578 - val_loss: 0.0339 - val_accuracy: 0.9889 - lr: 0.1000\\nEpoch 42/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1470 - accuracy: 0.9582 - val_loss: 0.0351 - val_accuracy: 0.9898 - lr: 0.1000\\nEpoch 43/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.1477 - accuracy: 0.9584 - val_loss: 0.0341 - val_accuracy: 0.9896 - lr: 0.1000\\nEpoch 44/100\\n600/600 [==============================] - 13s 21ms/step - loss: 0.1434 - accuracy: 0.9601 - val_loss: 0.0433 - val_accuracy: 0.9874 - lr: 0.1000\\nEpoch 45/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1472 - accuracy: 0.9595 - val_loss: 0.0389 - val_accuracy: 0.9885 - lr: 0.1000\\nEpoch 46/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1436 - accuracy: 0.9601 - val_loss: 0.0342 - val_accuracy: 0.9897 - lr: 0.1000\\nEpoch 47/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.1450 - accuracy: 0.9597 - val_loss: 5.6266 - val_accuracy: 0.7736 - lr: 0.1000\\nEpoch 48/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1405 - accuracy: 0.9615 - val_loss: 0.0437 - val_accuracy: 0.9887 - lr: 0.1000\\nEpoch 49/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1410 - accuracy: 0.9607 - val_loss: 0.0388 - val_accuracy: 0.9888 - lr: 0.1000\\nEpoch 50/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1400 - accuracy: 0.9619 - val_loss: 0.0398 - val_accuracy: 0.9897 - lr: 0.1000\\nEpoch 51/100\\n600/600 [==============================] - 12s 21ms/step - loss: 0.1359 - accuracy: 0.9626 - val_loss: 0.0327 - val_accuracy: 0.9898 - lr: 0.1000\\nEpoch 52/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1396 - accuracy: 0.9607 - val_loss: 0.0343 - val_accuracy: 0.9897 - lr: 0.1000\\nEpoch 53/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1353 - accuracy: 0.9635 - val_loss: 0.0371 - val_accuracy: 0.9893 - lr: 0.1000\\nEpoch 54/100\\n600/600 [==============================] - 13s 21ms/step - loss: 0.1336 - accuracy: 0.9620 - val_loss: 0.0367 - val_accuracy: 0.9890 - lr: 0.1000\\nEpoch 55/100\\n600/600 [==============================] - 13s 21ms/step - loss: 0.1313 - accuracy: 0.9632 - val_loss: 0.0407 - val_accuracy: 0.9898 - lr: 0.1000\\nEpoch 56/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1356 - accuracy: 0.9627 - val_loss: 0.0389 - val_accuracy: 0.9890 - lr: 0.1000\\nEpoch 57/100\\n600/600 [==============================] - 13s 21ms/step - loss: 0.1386 - accuracy: 0.9616 - val_loss: 0.0413 - val_accuracy: 0.9883 - lr: 0.1000\\nEpoch 58/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1332 - accuracy: 0.9634 - val_loss: 0.0372 - val_accuracy: 0.9881 - lr: 0.1000\\nEpoch 59/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1304 - accuracy: 0.9637 - val_loss: 0.0347 - val_accuracy: 0.9903 - lr: 0.1000\\nEpoch 60/100\\n600/600 [==============================] - 13s 21ms/step - loss: 0.1279 - accuracy: 0.9642 - val_loss: 0.0342 - val_accuracy: 0.9901 - lr: 0.1000\\nEpoch 61/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.1226 - accuracy: 0.9662 - val_loss: 0.0416 - val_accuracy: 0.9890 - lr: 0.1000\\nEpoch 62/100\\n600/600 [==============================] - 13s 21ms/step - loss: 0.1003 - accuracy: 0.9714 - val_loss: 0.0255 - val_accuracy: 0.9921 - lr: 0.0200\\nEpoch 63/100\\n600/600 [==============================] - 13s 21ms/step - loss: 0.0907 - accuracy: 0.9728 - val_loss: 0.0253 - val_accuracy: 0.9918 - lr: 0.0200\\nEpoch 64/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0865 - accuracy: 0.9740 - val_loss: 0.0245 - val_accuracy: 0.9915 - lr: 0.0200\\nEpoch 65/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0845 - accuracy: 0.9744 - val_loss: 0.0231 - val_accuracy: 0.9925 - lr: 0.0200\\nEpoch 66/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.0843 - accuracy: 0.9748 - val_loss: 0.0250 - val_accuracy: 0.9916 - lr: 0.0200\\nEpoch 67/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0833 - accuracy: 0.9751 - val_loss: 0.0235 - val_accuracy: 0.9925 - lr: 0.0200\\nEpoch 68/100\\n600/600 [==============================] - 13s 21ms/step - loss: 0.0834 - accuracy: 0.9737 - val_loss: 0.0230 - val_accuracy: 0.9923 - lr: 0.0200\\nEpoch 69/100\\n600/600 [==============================] - 13s 21ms/step - loss: 0.0772 - accuracy: 0.9766 - val_loss: 0.0232 - val_accuracy: 0.9925 - lr: 0.0200\\nEpoch 70/100\\n600/600 [==============================] - 13s 21ms/step - loss: 0.0782 - accuracy: 0.9764 - val_loss: 0.0235 - val_accuracy: 0.9914 - lr: 0.0200\\nEpoch 71/100\\n600/600 [==============================] - 13s 21ms/step - loss: 0.0771 - accuracy: 0.9772 - val_loss: 0.0235 - val_accuracy: 0.9918 - lr: 0.0200\\nEpoch 72/100\\n600/600 [==============================] - 13s 21ms/step - loss: 0.0782 - accuracy: 0.9765 - val_loss: 0.0241 - val_accuracy: 0.9919 - lr: 0.0200\\nEpoch 73/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0793 - accuracy: 0.9759 - val_loss: 0.0237 - val_accuracy: 0.9922 - lr: 0.0200\\nEpoch 74/100\\n600/600 [==============================] - 12s 21ms/step - loss: 0.0769 - accuracy: 0.9770 - val_loss: 0.0213 - val_accuracy: 0.9925 - lr: 0.0200\\nEpoch 75/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0755 - accuracy: 0.9768 - val_loss: 0.0241 - val_accuracy: 0.9916 - lr: 0.0200\\nEpoch 76/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0748 - accuracy: 0.9773 - val_loss: 0.0223 - val_accuracy: 0.9920 - lr: 0.0200\\nEpoch 77/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0741 - accuracy: 0.9767 - val_loss: 0.0225 - val_accuracy: 0.9924 - lr: 0.0200\\nEpoch 78/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0757 - accuracy: 0.9767 - val_loss: 0.0224 - val_accuracy: 0.9931 - lr: 0.0200\\nEpoch 79/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0738 - accuracy: 0.9775 - val_loss: 0.0233 - val_accuracy: 0.9927 - lr: 0.0200\\nEpoch 80/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0743 - accuracy: 0.9775 - val_loss: 0.0229 - val_accuracy: 0.9931 - lr: 0.0200\\nEpoch 81/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.0732 - accuracy: 0.9782 - val_loss: 0.0226 - val_accuracy: 0.9927 - lr: 0.0200\\nEpoch 82/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.0718 - accuracy: 0.9779 - val_loss: 0.0223 - val_accuracy: 0.9926 - lr: 0.0200\\nEpoch 83/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.0706 - accuracy: 0.9793 - val_loss: 0.0225 - val_accuracy: 0.9927 - lr: 0.0200\\nEpoch 84/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0704 - accuracy: 0.9776 - val_loss: 0.0228 - val_accuracy: 0.9927 - lr: 0.0200\\nEpoch 85/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0663 - accuracy: 0.9794 - val_loss: 0.0211 - val_accuracy: 0.9930 - lr: 0.0040\\nEpoch 86/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.0638 - accuracy: 0.9801 - val_loss: 0.0211 - val_accuracy: 0.9932 - lr: 0.0040\\nEpoch 87/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0644 - accuracy: 0.9801 - val_loss: 0.0205 - val_accuracy: 0.9934 - lr: 0.0040\\nEpoch 88/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0643 - accuracy: 0.9803 - val_loss: 0.0201 - val_accuracy: 0.9931 - lr: 0.0040\\nEpoch 89/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.0608 - accuracy: 0.9813 - val_loss: 0.0205 - val_accuracy: 0.9934 - lr: 0.0040\\nEpoch 90/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0622 - accuracy: 0.9805 - val_loss: 0.0206 - val_accuracy: 0.9928 - lr: 0.0040\\nEpoch 91/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0605 - accuracy: 0.9806 - val_loss: 0.0206 - val_accuracy: 0.9924 - lr: 0.0040\\nEpoch 92/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0595 - accuracy: 0.9818 - val_loss: 0.0201 - val_accuracy: 0.9933 - lr: 0.0040\\nEpoch 93/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0639 - accuracy: 0.9803 - val_loss: 0.0202 - val_accuracy: 0.9932 - lr: 0.0040\\nEpoch 94/100\\n600/600 [==============================] - 13s 21ms/step - loss: 0.0625 - accuracy: 0.9806 - val_loss: 0.0207 - val_accuracy: 0.9927 - lr: 0.0040\\nEpoch 95/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0607 - accuracy: 0.9812 - val_loss: 0.0211 - val_accuracy: 0.9927 - lr: 0.0040\\nEpoch 96/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.0597 - accuracy: 0.9814 - val_loss: 0.0202 - val_accuracy: 0.9933 - lr: 0.0040\\nEpoch 97/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0628 - accuracy: 0.9803 - val_loss: 0.0202 - val_accuracy: 0.9932 - lr: 0.0040\\nEpoch 98/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0611 - accuracy: 0.9803 - val_loss: 0.0202 - val_accuracy: 0.9931 - lr: 0.0040\\nEpoch 99/100\\n600/600 [==============================] - 13s 22ms/step - loss: 0.0620 - accuracy: 0.9808 - val_loss: 0.0200 - val_accuracy: 0.9932 - lr: 8.0000e-04\\nEpoch 100/100\\n600/600 [==============================] - 14s 23ms/step - loss: 0.0603 - accuracy: 0.9813 - val_loss: 0.0201 - val_accuracy: 0.9931 - lr: 8.0000e-04\\nTest loss: 0.02010110579431057\\nTest accuracy: 0.9930999875068665\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"RNA-MNIST.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1xsGYJ98ShBFwrAi8nZ4ck8xTQhnaFcJR\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Reshape, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization as BN\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import GaussianNoise as GN\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def add_layers(model: keras.models.Model, block: int):\n",
    "    model.add(Dense(1024, name=f\"dense_block{block}\"))\n",
    "    model.add(BN(name=f\"bach_normalization_block{block}\"))\n",
    "    model.add(GN(0.3, name=f\"gaussian_noise_block{block}\"))\n",
    "    model.add(Activation('relu', name=f\"relu_block{block}\"))\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 100\n",
    "num_classes = 10\n",
    "blocks = 5\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('training set', x_train.shape)\n",
    "print('test set', x_test.shape)\n",
    "\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize [0..255]-->[0..1]\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Data Augmentation with an ImageGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rotation_range=10\n",
    ")\n",
    "\n",
    "# Model, note the reshape\n",
    "model = Sequential()\n",
    "model.add(Reshape(target_shape=(784,), input_shape=(28, 28, 1)))\n",
    "model.add(GN(0.3))\n",
    "\n",
    "for i in range(blocks):\n",
    "    add_layers(model, i)\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "sgd = Adam(learning_rate=0.1)\n",
    "set_lr = ReduceLROnPlateau( monitor='val_loss', factor=0.2, patience=10, min_lr=1e-6)\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=sgd,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "    steps_per_epoch=len(x_train) / batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[set_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a574ebe25ba7c7aaf3824aa551855f88c0879d5c5c83cc50c0532cd155652f26"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
